## 1. 캐시란 무엇인가?

+ Cache(캐시)란 데이터의 원본이나 원본 데이터를 통해 연산된 값을 미리 저장(복사)해두는 임시 저장소를 의미한다. 즉, 데이터의 읽기(Read) 성능을 개선시키기 위해 DB와 같은 영구 저장소로부터 로드된 데이터를 빠르게 읽어올 수 있는 Memory 영역에 저장해두는 방식인 것이다. 캐싱을 사용하면 이후에 해당 데이터에 대한 요청이 있을 경우 데이터의 기본 스토리지 위치에 액세스할 때보다 더 빠르게 요청을 처리할 수 있다. 

+ 기본적인 Key-Value 타입을 사용하게 되면 쿼리를 파싱하는 시간도 없어지고, 접근 속도가 훨씬 빠른 메모리에서 읽어오게 되기 때문에 많은 속도 차이가 나게 된다. 따라서 캐싱을 사용하면 이전에 검색하거나 계산한 데이터를 효율적으로 재사용할 수 있다.

+ 메모리 기술은 주로 DRAM과 SRAM으로 나뉘는데, DRAM은 가격이 싸고 용량 대비 크기가 작지만 속도가 느리고, SRAM은 속도는 빠르지만 가격이 비싸고 용량 대비 크기가 크다는 단점이 있다. 그래서 DRAM을 사용자가 직접 장착하게 하는 대신, CPU와 DRAM 사이에 SRAM을 별도로 두어서 DRAM의 데이터를 직접 접근하는 것보다는 빠르게 접근할 수 있도록 한다. 여기에 사용하는 SRAM을 캐시 메모리라고 한다. 물론 어디까지나 현세대 기준 일반적인 경우이고, SRAM이 무조건 캐시로만 활용된 것은 아니며, DRAM도 캐시로 활용될 수 있다.
  + 시스템에 장착된 캐시의 용량과 성능이 점점 증가하면서 캐시의 캐시로 사용되는 메모리가 추가되었는데, 이것을 적용된 순서대로 L(Level) 1, L2, L3 ... 라고 호칭한다. L1에 가장 고성능이자 고가인 작은 용량의 집적회로가 사용되고, L1캐시에서 데이터를 퍼가기 위한 캐시로 사용하기 위해 그보다는 용량이 크지만 그 대신 약간 더 느린 저장공간이 추가되었으며, L2캐시에서 데이터를 퍼가기 위한 캐시로 이후 L3 캐시가 추가되었고... 하는 식이다.

<br/>

<br/>

### 1.1 원리

+ 캐시 메모리는 **데이터 지역성(Locality)**의 원리를 이용한다. 데이터 지역성은 시간 지역성(Temporal locality), 공간 지역성(Spatial Locality), 순차적 지역성(Sequential Locality)으로 나뉜다.
  + 시간 지역성
    + for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시 후에 또 참조될 가능성이 높다는 것
  + 공간 지역성
    + A[0], A[1]과 같은 데이터 배열에 연속으로 접근할 때 참조된 데이터 근처에 있는 데이터가 잠시 후에 사용될 가능성이 높다는 것
  + 순차적 지역성
    + 분기(branch)가 발생하는 비순차적 실행이 아닌 이상 명령어들이 메모리에 저장된 순서대로 실행하는 특성을 이용한 원리로 순차적일 수록 다음 순서의 데이터가 사용될 가능성이 높다는 것

<br/>

<br/>

### 1.2 캐시 히트와 캐시 미스

+ 캐시의 성능을 측정할 때는 히트 레이턴시(Hit latency)와 미스 레이턴시(Miss latency)가 중요한 요인으로 꼽힌다.

+ CPU에서 요청한 데이터가 캐시에 존재하는 경우를 캐시 히트(Hit)라고 한다. 히트 레이턴시는 히트가 발생해 캐싱된 데이터를 가져올 때 소요되는 시간을 의미한다. 반면 요청한 데이터가 캐시에 존재하지 않는 경우를 캐시 미스(Miss)라고 하며, 미스 레이턴시는 미스가 발생해 상위 캐시에서 데이터를 가져오거나(L1 캐시에 데이터가 없어서 L2 캐시에서 데이터를 찾는 경우) 메모리에서 데이터를 가져올 때 소요되는 시간을 말한다.

+ 평균 접근 시간(Average access time)은 다음과 같이 구한다.
  + Miss rate = Cache misses / Cache accesses
  + Average access time = Hit latency + Miss rate * Miss latency

+ 캐시의 성능을 높이기 위해서는 캐시의 크기를 줄여 히트 레이턴시를 줄이거나, 캐시의 크기를 늘려 미스 비율을 줄이거나, 더 빠른 캐시를 이용해 레이턴시를 줄이는 방법이 있다.







## 2. 웹 애플리케이션 아키텍처와 병목 구간

![js1](http://clipsoft.co.kr/wp/wp-content/uploads/2020/09/js1-748x133.png)

![img](https://media.vlpt.us/images/y_dragonrise/post/7044b34e-2edf-4148-a447-ea34f6d9dca8/image.png)

+ 웹 브라우저
  + Request / Resonse
  + HTML과 CSS 명세에 따라 HTML 파일 해석 및 표시
+ 웹 서버
  + 클라이언트로부터 HTTP 방식으로 **정적 파일**(HTML, images, CSS, JS 등)을 요청받아 그에 맞는 응답을 반환하는 서버
  + SSL(암복호화 처리)
  + 접근 허용 IP 관리
  + Apache, IIS, 엔터프라이즈 서버 등
+ 웹 애플리케이션 서버
  + 웹 서버에서 처리할 수 없는 **동적인 정보**를 처리하여 웹 서버에 정적인 정보를 제공, 주로 데이터베이스 서버와 같이 수행됨
  + 일반적으로 웹 서버의 기능을 내제하고 있어 웹 서버 없이도 서비스 가능
  + Web Logic, Jeus, Tomcat 등

<br/>

<br/>

### 2.1 병목 구간

+ 트래픽이 많을 경우 WAS와 데이터베이스 사이에서 트랜잭션이 일어날 때 후순위의 트랜잭션이 매우 늦게 처리되는 경우가 발생할 수 있다. 즉, TPS(초당 트랜잭션 처리 수)를 넘는 요청이 1초 안에 들어오면 당연히 사용자는 그만큼 응답을 늦게 받게 된다.
+ 아키텍처에서 웹 서버는 정적인 파일을 반환하기 때문에 미리 저장되어 있는 파일을 제공하기만 하면 된다. 하지만, 웹 애플리케이션 서버에서는 사용자의 요청에 따라 해당 요청에 응답하기 위한 동적 정보를 데이터베이스로부터 받아와야 하기 때문에 이 부분에서 캐싱이 없을 경우 데이터의 기본 스토리지까지 훑으러 내려가면서 시간이 오래 걸리며 병목 현상이 발생하게 되는 것이다.